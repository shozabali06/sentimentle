{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46aa1329",
   "metadata": {},
   "source": [
    "# Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f4d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # importing pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "185725a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./datasets/training.1600000.processed.noemoticon.csv', encoding='ISO-8859-1', header=None) # reading the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6592fa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0           1                             2         3                4  \\\n",
      "0  0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
      "1  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
      "2  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
      "3  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
      "4  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
      "\n",
      "                                                   5  \n",
      "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
      "1  is upset that he can't update his Facebook by ...  \n",
      "2  @Kenichan I dived many times for the ball. Man...  \n",
      "3    my whole body feels itchy and like its on fire   \n",
      "4  @nationwideclass no, it's not behaving at all....  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1fd5fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   target  1600000 non-null  int64 \n",
      " 1   ids     1600000 non-null  int64 \n",
      " 2   date    1600000 non-null  object\n",
      " 3   flag    1600000 non-null  object\n",
      " 4   user    1600000 non-null  object\n",
      " 5   text    1600000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 73.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df.columns = ['target', 'ids', 'date', 'flag', 'user', 'text'] # assigning column names\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faad78bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target                                               text\n",
      "0       0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1       0  is upset that he can't update his Facebook by ...\n",
      "2       0  @Kenichan I dived many times for the ball. Man...\n",
      "3       0    my whole body feels itchy and like its on fire \n",
      "4       0  @nationwideclass no, it's not behaving at all....\n"
     ]
    }
   ],
   "source": [
    "df = df[['target', 'text']] # selecting only target and text columns\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80f16d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    800000\n",
       "4    800000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts() # counting occurrences of each unique row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59fa827",
   "metadata": {},
   "source": [
    "# Data Cleaning And Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "419cd6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Shozab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Shozab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Shozab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() # convert to lowercase\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) # remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text) # remove mentions\n",
    "    text = re.sub(r'#(\\w+)', r'\\1', text)  # remove hashtags but keep the text\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text) # remove numbers\n",
    "    text = text.strip() # remove leading and trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text) # Replace multiple spaces with a single space\n",
    "\n",
    "    tokens = nltk.word_tokenize(text) # tokenize the text\n",
    "    tokens = [word for word in tokens if word not in nltk.corpus.stopwords.words('english')] # remove stopwords\n",
    "    tokens = [nltk.stem.PorterStemmer().stem(word) for word in tokens] # stemming\n",
    "    text = ' '.join(tokens) # join tokens back to string\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bef4cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['text'].apply(clean_text) # applying the cleaning function to the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9125a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('text', axis=1) # dropping the original text column\n",
    "df.to_csv('cleaned_tweets.csv', index=False) # saving the cleaned data to a new csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e6414c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   target                                       cleaned_text\n",
      "0       0       that bummer shoulda got david carr third day\n",
      "1       0  upset cant updat facebook text might cri resul...\n",
      "2       0       dive mani time ball manag save rest go bound\n",
      "3       0                    whole bodi feel itchi like fire\n",
      "4       0                              behav im mad cant see\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = pd.read_csv('./datasets/cleaned_tweets.csv') # reading the cleaned data\n",
    "print(cleaned_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f26bdb3",
   "metadata": {},
   "source": [
    "# Model Training, Evaluation, and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e939317f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        cleaned_text sentiment\n",
      "0       that bummer shoulda got david carr third day  negative\n",
      "1  upset cant updat facebook text might cri resul...  negative\n",
      "2       dive mani time ball manag save rest go bound  negative\n",
      "3                    whole bodi feel itchi like fire  negative\n",
      "4                              behav im mad cant see  negative\n"
     ]
    }
   ],
   "source": [
    "# Rename target column to sentiment and map values\n",
    "df['sentiment'] = df['target'].map({0: 'negative', 4: 'positive'})\n",
    "df = df.drop('target', axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d55c3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08056460",
   "metadata": {},
   "outputs": [],
   "source": [
    "TfidfVectorizer = TfidfVectorizer(max_features=3000) # initializing the TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "020dbfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['cleaned_text'] # features\n",
    "y = df['sentiment'] # target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea15729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = TfidfVectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3c1e430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ab' 'abl' 'absolut' 'abt' 'ac' 'accent' 'accept' 'access' 'accid'\n",
      " 'accident' 'accomplish' 'accord' 'account' 'ace' 'ach' 'across' 'act'\n",
      " 'action' 'activ' 'actor' 'actual' 'ad' 'adam' 'add' 'addict' 'address'\n",
      " 'admit' 'adopt' 'ador' 'adult' 'advanc' 'adventur' 'advertis' 'advic'\n",
      " 'afford' 'afraid' 'afternoon' 'afterward' 'age' 'ago' 'agre' 'ah' 'aha'\n",
      " 'ahah' 'ahaha' 'ahead' 'ahh' 'ahhh' 'ahhhh' 'ahhhhh']\n"
     ]
    }
   ],
   "source": [
    "# To see the words the vectorizer chose as features:\n",
    "print(TfidfVectorizer.get_feature_names_out()[:50]) # Print the first 50 words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3aee0d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42) # splitting the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a0b139a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f64e20",
   "metadata": {},
   "source": [
    "## Model A (Baseline): Train a LogisticRegression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aed2f923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Logistic Regression model...\n",
      "Logistic Regression model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "log_reg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "print(\"Training the Logistic Regression model...\")\n",
    "\n",
    "# Train the model on the training data\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Logistic Regression model trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "823a7b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 76.77%\n",
      "\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.75      0.76    159494\n",
      "    positive       0.76      0.79      0.77    160506\n",
      "\n",
      "    accuracy                           0.77    320000\n",
      "   macro avg       0.77      0.77      0.77    320000\n",
      "weighted avg       0.77      0.77      0.77    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_log_reg = log_reg_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_log_reg * 100:.2f}%\")\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(\"\\nClassification Report for Logistic Regression:\")\n",
    "print(classification_report(y_test, y_pred_log_reg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc59ad45",
   "metadata": {},
   "source": [
    "## Model B (Advanced): Train a RandomForestClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "224f7040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the Random Forest model... (This may take several minutes)\n",
      "Random Forest model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest Classifier model\n",
    "# n_estimators=100 means it will build 100 decision trees.\n",
    "# n_jobs=-1 uses all available CPU cores to make training faster.\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "print(\"\\nTraining the Random Forest model... (This may take several minutes)\")\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Random Forest model trained successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ced93a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 76.89%\n",
      "\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.77      0.77    159494\n",
      "    positive       0.77      0.77      0.77    160506\n",
      "\n",
      "    accuracy                           0.77    320000\n",
      "   macro avg       0.77      0.77      0.77    320000\n",
      "weighted avg       0.77      0.77      0.77    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Accuracy: {accuracy_rf * 100:.2f}%\")\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(\"\\nClassification Report for Random Forest:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c2e30e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model for saving: LogisticRegression\n",
      "Model saved successfully to ./models/sentiment_model.pkl\n",
      "Vectorizer saved successfully to ./models/vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# --- Step 1: Explicitly choose the Logistic Regression model ---\n",
    "# Based on our analysis, it provides the same performance with better speed.\n",
    "best_model = log_reg_model\n",
    "print(f\"Selected model for saving: {type(best_model).__name__}\")\n",
    "\n",
    "\n",
    "# --- Step 2: Define the filepaths ---\n",
    "model_filepath = './models/sentiment_model.pkl'\n",
    "vectorizer_filepath = './models/vectorizer.pkl'\n",
    "\n",
    "\n",
    "# --- Step 3: Save both the model and the vectorizer ---\n",
    "# Save the trained model to a file\n",
    "joblib.dump(best_model, model_filepath)\n",
    "print(f\"Model saved successfully to {model_filepath}\")\n",
    "\n",
    "# Save the TF-IDF vectorizer to a file\n",
    "# (This is the same vectorizer you used for both models)\n",
    "joblib.dump(TfidfVectorizer, vectorizer_filepath)\n",
    "print(f\"Vectorizer saved successfully to {vectorizer_filepath}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
